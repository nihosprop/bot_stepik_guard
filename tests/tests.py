import html
import json
import logging
import re

import unicodedata
from Levenshtein import distance
from pathlib import Path

from better_profanity import profanity

from filters.patterns import DataProfanity

logger_tests = logging.getLogger(__name__)

test_cases = [
    # –ë–∞–∑–æ–≤—ã–µ –º–∞—Ç–µ—Ä–Ω—ã–µ —Å–ª–æ–≤–∞
    ("—Ö—É–π", True),
    ("–ø–∏–∑–¥–∞", True),
    ("–µ–±–∞–ª", True),
    ("–±–ª—è–¥—å", True),
    ("—Å—É–∫–∞", True),
    ("–≥–æ–Ω–¥–æ–Ω", True),
    ("–º—É–¥–∞–∫", True),
    ("–∑–∞–ª—É–ø–∞", True),
    ("—à–ª—é—Ö–∞", True),
    ("–ø–∏–¥–æ—Ä", True),
    
    # –û–±—ã—á–Ω—ã–µ —Å–ª–æ–≤–∞ (–Ω–µ –¥–æ–ª–∂–Ω—ã —Ç—Ä–∏–≥–≥–µ—Ä–∏—Ç—å)
    ("—Ö–æ—Ä–æ—à–∏–π", False),
    ("–ø—Ä–µ–∫—Ä–∞—Å–Ω–æ", False),
    ("–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ", False),
    ("–æ–±—ã—á–Ω—ã–π", False),
    ("—Å–ª–æ–≤–æ", False),
    ("—Ñ–∏–ª—å—Ç—Ä", False),
    ("–ø—Ä–æ–≤–µ—Ä–∫–∞", False),
    
    # –û–ø–µ—á–∞—Ç–∫–∏ –∏ –∑–∞–º–µ–Ω—ã —Å–∏–º–≤–æ–ª–æ–≤
    ("—Ö@–π", True),
    ("–ø!–∑–¥–∞", True),
    ("–µ6–∞–ª", True),
    ("–±–ª—èd—å", True),
    ("—Å—Ék–∞", True),
    ("–≥0–Ω–¥–æ–Ω", True),
    ("–º—Éd–∞–∫", True),
    ("–∑–∞–ª—É–ø@", True),
    ("—à–ª—éx–∞", True),
    ("–ø–∏d0—Ä", True),
    ("xy–π", True),
    ("–øi–∑–¥–∞", True),
    ("–µ–±a–ª", True),
    ("–±–ª9–¥—å", True),
    ("—Åy–∫–∞", True),
    ("–≥–∞–Ω–¥–æ–Ω", True),
    ("–º—É–¥@–∫", True),
    ("–∑–∞–ª—É–øa", True),
    ("—à–ª—å—É—Ö–∞", True),
    ("–øi–¥–æ—Ä", True),
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Å–∏–º–≤–æ–ª–∞–º–∏
    ("—Ö —É –π", True),
    ("–ø-–∏–∑–¥–∞", True),
    ("–µ–±@–ª", True),
    ("–±–ª*—è–¥—å", True),
    ("—Å —É –∫ –∞", True),
    ("–≥ –æ –Ω –¥ –æ –Ω", True),
    ("–º —É –¥ –∞ –∫", True),
    ("–∑ –∞ –ª —É –ø –∞", True),
    ("—à –ª —é —Ö –∞", True),
    ("–ø –∏ –¥ –æ —Ä", True),
    ("—Ö.—É.–π", True),
    ("–ø!–∑!–¥!–∞", True),
    ("–µ#–±@–∞@–ª", True),
    ("–±$–ª%—è^–¥—å", True),
    ("—Å*—É*–∫*–∞", True),
    
    # –ü–æ–≤—Ç–æ—Ä–µ–Ω–∏—è —Å–∏–º–≤–æ–ª–æ–≤
    ("—Ö—É—É—É–π", True),
    ("–ø–ø–ø–∏–∑–¥–∞", True),
    ("–µ–µ–µ–±–∞–ª", True),
    ("–±–ª—è—è—è–¥—å", True),
    ("—Å—É—É—É–∫–∞", True),
    ("–≥–æ–æ–æ–Ω–¥–æ–Ω", True),
    ("–º—É—É–¥–∞–∫", True),
    ("–∑–∞–ª—É—É—É–ø–∞", True),
    ("—à–ª—é—é—é—Ö–∞", True),
    ("–ø–∏–∏–∏–¥–æ—Ä", True),
    ("—Ö—Ö—Ö—Ö—Ö", True),
    ("–ø–ø–ø–ø–ø", True),
    ("–µ–µ–µ–µ–µ", True),
    ("–±–±–±–±–±", True),
    ("—Å—Å—Å—Å—Å", True),
    
    # –°–º–µ—à–∞–Ω–Ω—ã–µ —è–∑—ã–∫–∏
    ("h—É–π", True),
    ("p–∏–∑–¥–∞", True),
    ("e–±–∞–ª", True),
    ("bl—è—Ç—å", True),
    ("cy–∫–∞", True),
    ("g–æ–Ω–¥–æ–Ω", True),
    ("m—É–¥–∞–∫", True),
    ("z–∞–ª—É–ø–∞", True),
    ("—àl—é—Ö–∞", True),
    ("p–∏–¥–æ—Ä", True),
    ("x—Éj", True),
    ("–øi–∑d–∞", True),
    ("–µ–±a1", True),
    ("–±–ª9d—å", True),
    ("—Å—Ék–∞", True),
    
    # –ö—Ä–∞—Ç–∫–∏–µ —Ñ–æ—Ä–º—ã –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ
    ("—Ö–µ—Ä", True),
    ("—Ö—Ä–µ–Ω", True),
    ("–ø–∏–∑–¥", True),
    ("–µ–±", False),
    ("–±–ª—è", True),
    ("—Å—É–∫", True),
    ("–≥–æ–Ω", True),
    ("–º—É–¥", True),
    ("–∑–∞–ª", True),
    ("–ø–∏–¥", True),
    ("—Ö—É–µ–≤", True),
    ("–ø–∏–∑–¥–µ—Ü", True),
    ("–µ–±–∞–Ω—É—Ç—ã–π", True),
    ("–±–ª—è–¥—Å–∫–∏–π", True),
    ("—Å—É—á–∞—Ä–∞", True),
    ("–≥–∞–Ω–¥–æ–Ω—Å–∫–∏–π", True),
    ("–º—É–¥–∞—Ü–∫–∏–π", True),
    ("–∑–∞–ª—É–ø–∏—Ç—å—Å—è", True),
    ("—à–ª—é—à–∏–Ω—ã–π", True),
    ("–ø–∏–¥–æ—Ä–∞—Å–∏–Ω–∞", True),
    
    # –û–±—Ö–æ–¥ —á–µ—Ä–µ–∑ Unicode (–≥–æ–º–æ–≥–ª–∏—Ñ—ã)
    ("—Ö·•ô–π", True),
    ("–ø—ñ–∑–¥–∞", True),
    ("–µ–±…ë–ª", True),
    ("–±‚Öº—è–¥—å", True),
    ("—ï—É–∫–∞", True),
    ("…°–æ–Ω–¥–æ–Ω", True),
    ("ÔΩç—É–¥–∞–∫", True),
    ("·¥¢–∞–ª—É–ø–∞", True),
    ("—à…≠—é—Ö–∞", True),
    ("—Ä—ñ–¥–æÔΩí", True),
    ("“ª—É–π", True),
    ("—Äizd–∞", True),
    ("–µ—å–∞–ª", True),
    ("—å–ª—è–¥—å", True),
    ("—ï—Ü–∫–∞", True),
    
    # –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ –∫–µ–π—Å—ã (–ª–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è)
    ("—Ö—É–¥–æ–∂–Ω–∏–∫", False),
    ("–ø–æ–∑–Ω–∞–Ω–∏–µ", False),
    ("–±–µ–ª—ã–π", False),
    ("—Å—É–∫–∫—É–ª–µ–Ω—Ç", False),
    ("–≥–æ–ª—É–±–æ–π", False),
    ("–º—É–¥–∞—á–æ–∫", False),
    ("—à–ª—é–º–±–µ—Ä—å–µ", False),
    ("–ø–∏–¥–∂–∞–∫–∏", False),
    ("—Ö–µ—Ä—Å–æ–Ω–µ—Å", False),
    ("—Ö—É–ª–∏–≥–∞–Ω", False),
    
    # –°–ª–æ–∂–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
    ("–¥–∞—Ç—ã–¥–∏–Ω–∞—Ö@–π", True),
    ("–ø–æ–¥–ø–∏–∑–¥@—à–∏—Ç—å", True),
    ("—Ä–∞–∑—ä–µ–±–∞—à–∏—Ç—å", True),
    ("—É–±–ª—é–¥–æ–∫—Å—É—á@", True),
    ("–≥–∞–Ω–¥–æ–Ω–æ–ø–æ–¥–æ–±–Ω—ã–π", True),
    ("–º—É–¥–∞–∫–æ–≤–∞—Ç—ã–π", True),
    ("–∑–∞–ª—É–ø–∏–Ω–æ–≥–æ–ª–æ–≤—ã–π", True),
    ("—à–ª—é—Ö–æ–º–æ–π–∫–∞", True),
    ("–ø–∏–¥–æ—Ä–∞—à–∫–∞", True),
    ("—Ö–µ—Ä–æ—Å—Ä–∞—á", True),
    ("–ø–∏–∑–¥–∞–±–æ–ª", True),
    ("–µ–±–∞–Ω—É—Ç—å—Å—è", True),
    ("–±–ª—è–¥–æ—Å–ª–æ–≤", True),
    ("—Å—É–∫–æ—ë–±", True),
    ("–≥–∞–Ω–¥–æ–Ω–æ–º–∞—Ç", True),
    ("–º—É–¥–∞–∫–æ–∏–¥", True),
    ("–∑–∞–ª—É–ø–æ–≥–ª–∞–∑", True),
    ("—à–ª—é—Ö–æ–¥—Ä–æ—á", True),
    ("–ø–∏–¥–æ—Ä–≤–∞–Ω–µ—Ü", True),
    ("—Ö–µ—Ä–æ–º–∞–Ω—Ç–∏—è", True),
    
    # –ì—Ä–∞–Ω–∏—á–Ω—ã–µ –∫–µ–π—Å—ã
    ("", False),
    (" ", False),
    ("   ", False),
    ("!@#$%", False),
    ("12345", False),
    ("–∞–±–≤–≥–¥", False),
    ("—Ö", False),
    ("—Ö—É", False),
    ("—Ö—É—é", True),
    ("—Ö—É—é—à", True),
    ("–∞", False),
    ("–±", False),
    ("–≤", False),
    ("–≥", False),
    ("–¥", False),
    ("–µ", False),
    ("—ë", False),
    ("–∂", False),
    ("–∑", False),
    ("–∏", False),
    
    # –î–ª–∏–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã —Å –º–∞—Ç–æ–º
    ("–≠—Ç–æ —Ç–µ–∫—Å—Ç —Å —Ö—É—ë–º –ø–æ—Å–µ—Ä–µ–¥–∏–Ω–µ", True),
    ("–í–æ—Ç —Ç–∞–∫–∞—è –ø–∏–∑–¥–µ—Ü —Å–∏—Ç—É–∞—Ü–∏—è", True),
    ("–ù—É —Ç—ã –∏ –±–ª—è–¥—å", True),
    ("–°—É—á–∫–∞ —Ç—ã –∫–æ–Ω—á–µ–Ω–Ω–∞—è", True),
    ("–ì–∞–Ω–¥–æ–Ω —Ç—ã –µ–±–∞–Ω—ã–π", True),
    ("–ú—É–¥–∞–∫ –≤–æ–Ω—é—á–∏–π", True),
    ("–ó–∞–ª—É–ø–∞ –∫—Ä–∏–≤–∞—è", True),
    ("–®–ª—é—Ö–∞ —Ç—ã —Ç—É–ø–∞—è", True),
    ("–ü–∏–¥–æ—Ä –Ω–µ—Å—á–∞—Å—Ç–Ω—ã–π", True),
    ("–•—É–π —Ç–µ–±–µ –∞ –Ω–µ –æ—Ç–≤–µ—Ç", True),
    
    # –¢–µ–∫—Å—Ç –±–µ–∑ –º–∞—Ç–∞ (–Ω–µ –¥–æ–ª–∂–µ–Ω —Ç—Ä–∏–≥–≥–µ—Ä–∏—Ç—å)
    ("–≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏–π", False),
    ("–ü—Ä–æ—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç—ã —Ñ–∏–ª—å—Ç—Ä–∞", False),
    ("–ù–∏–∫–∞–∫–∏—Ö –ø–ª–æ—Ö–∏—Ö —Å–ª–æ–≤ –∑–¥–µ—Å—å –Ω–µ—Ç", False),
    ("–•–æ—Ä–æ—à–∏–π –¥–µ–Ω—å –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è", False),
    ("–§–∏–ª—å—Ç—Ä –¥–æ–ª–∂–µ–Ω –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç", False),
    
    # –≠–≤—Ñ–µ–º–∏–∑–º—ã –∏ –∑–∞–≤—É–∞–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏—è
    ("—Ö****–π", True),
    ("–ø****–∞", True),
    ("******", False),
    ("–±****—å", True),
    ("—Å***–∞", True),
    ("****–æ–Ω", True),
    ("–º***–∫", True),
    ("–∑****–∞", True),
    ("—à***–∞", True),
    ("–ø****—Ä", True),
    ("—Ö*–π", True),
    ("–ø*–∑–¥–∞", True),
    ("*–±–∞–ª", True),
    ("–±–ª*–¥—å", True),
    ("—Å*–∫–∞", True),
    ("–≥*–Ω–¥–æ–Ω", True),
    ("–º*–¥–∞–∫", True),
    ("–∑*–ª—É–ø–∞", True),
    ("—à*–ª—é—Ö–∞", True),
    ("–ø*–¥–æ—Ä", True),
    
    # –¢–≤–æ—Ä—á–µ—Å–∫–∏–µ –Ω–∞–ø–∏—Å–∞–Ω–∏—è
    ("—Ö—É–π–ª–∞–Ω–¥–∏—è", True),
    ("–ø–∏–∑–¥–∞–±–æ–ª–∏—â–µ", True),
    ("–µ–±–∞–Ω—å–∫–æ", True),
    ("–±–ª—è–¥—é–≥–∞", True),
    ("—Å—É–∫–æ–¥–µ–ª", False),
    ("–≥–∞–Ω–¥–æ–Ω—á–∏–∫", True),
    ("–º—É–¥–∞—á–∏–Ω–∞", True),
    ("–∑–∞–ª—É–ø–µ–Ω—å", True),
    ("—à–ª—é—à–µ–Ω—Ü–∏—è", True),
    ("–ø–∏–¥–æ—Ä–∞–º–∞", True),
    ("—Ö—É—è–∫", True),
    ("–ø–∏–∑–¥–∞–∫", True),
    ("–µ–±–∞–∫–ª–∞–∫", True),
    ("–±–ª—è–º–±–∞", True),
    ("—Å—É–∫–æ—Ç–Ω–∏–∫", True),
    ("–≥–∞–Ω–¥–æ–Ω—é–∫", True),
    ("–º—É–¥–∞—á—å–µ", True),
    ("–∑–∞–ª—É–ø–ª—è–Ω–¥–∏—è", True),
    ("—à–ª—é—Ö–µ–Ω—Ü–∏—è", True),
    ("–ø–∏–¥–æ—Ä—é–≥–∞", True),
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã
    ("—Ö–µ—Ä", True),
    ("–∂–æ–ø", False),
    ("–¥—Ä–æ", False),
    ("—Å—É—á", False),
    ("–≥–Ω–¥", False),
    ("–º–¥–∫", False),
    ("–∑–ª–ø", False),
    ("—à–ª—Ö", False),
    ("–ø–¥—Ä", False),
    ("—Ö–π", False),
    
    # –ß–∏—Å–ª–æ–≤—ã–µ –∑–∞–º–µ–Ω—ã (leet speak)
    ("xy1", True),
    ("p1zd@", True),
    ("3ba7", True),
    ("6149b", True),
    ("cyk@", True),
    ("607d0h", False),
    ("myd@k", True),
    ("241upa", False),
    ("sh1ux@", True),
    ("nud0p", True),
    ("x|_|–π", True),
    ("|o|–∑–¥–∞", True),
    ("—ë—å–∞1", True),
    ("6–ª—è9—å", True),
    ("(_)–∫–∞", True),
    
    # –ö–æ–º–±–∏–Ω–∞—Ü–∏–∏ —Å —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
    ("–∞—Ö—É–µ–Ω–Ω—ã–π", True),
    ("–ø–∏–∑–¥–∞—Ç—ã–π", True),
    ("–µ–±–∞–Ω—É—Ç—å—Å—è", True),
    ("–±–ª—è–¥—Å–∫–∏–π", True),
    ("—Å—É–∫–∞ —Ç—ã", True),
    ("–≥–∞–Ω–¥–æ–Ω—Å–∫–∏–π", True),
    ("–º—É–¥–∞–∫–æ–≤–∞—Ç—ã–π", True),
    ("–∑–∞–ª—É–ø–∏—Ç—å—Å—è", True),
    ("—à–ª—é—à–∏–Ω—ã–π", True),
    ("–ø–∏–¥–æ—Ä–∞—à–∫–∞", True),
    ("–æ—Ö—É–µ—Ç—å", True),
    ("—Ä–∞—Å–ø–∏–∑–¥–µ—Ç—å—Å—è", True),
    ("–¥–æ–µ–±—ã–≤–∞—Ç—å—Å—è", True),
    ("—É–±–ª—è–¥–æ–∫", True),
    ("–ø–æ–¥—Å—É–∫–∞", True),
    ("–≥–∞–Ω–¥–æ–Ω—á–∏–∫", True),
    ("–º—É–¥–∞—á–∏–Ω–∞", True),
    ("–∑–∞–ª—É–ø–µ–Ω—å", True),
    ("—à–ª—é—à–µ–Ω—Ü–∏—è", True),
    ("–ø–∏–¥–æ—Ä–∞–º–∞", True),
    
    # –ò–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ (–Ω–µ –¥–æ–ª–∂–Ω—ã —Ç—Ä–∏–≥–≥–µ—Ä–∏—Ç—å)
    ("hello", False),
    ("shit", True),
    ("fuck", True),
    ("bitch", True),
    ("asshole", True),
    ("damn", True),
    ("cunt", True),
    ("dick", True),
    ("pussy", True),
    ("bastard", True),
    
    # –°–ª–æ–∂–Ω—ã–µ —é–Ω–∏–∫–æ–¥-–∫–µ–π—Å—ã
    ("—Ö\u0435—Ä", True),
    ("–ø\u0456–∑–¥–∞", True),
    ("\u0435–±–∞–ª", True),
    ("–±–ª\u044f–¥—å", True),
    ("—Å\u0443–∫–∞", True),
    ("\u0433–æ–Ω–¥–æ–Ω", True),
    ("–º\u0443–¥–∞–∫", True),
    ("–∑\u0430–ª—É–ø–∞", True),
    ("—à\u043b—é—Ö–∞", True),
    ("–ø\u0438–¥–æ—Ä", True),
    ("—Ö\u200b—É–π", True),
    ("–ø\u200c–∏–∑–¥–∞", True),
    ("–µ\u200d–±–∞–ª", True),
    ("–±\u200e–ª—è–¥—å", True),
    ("—Å\u200f—É–∫–∞", True),
    
    # –≠–º–æ–¥–∑–∏ –∏ —Å–∏–º–≤–æ–ª—ã
    ("—Ö—É–π üòà", True),
    ("–ø–∏–∑–¥–∞ üî•", True),
    ("–µ–±–∞–ª üñï", True),
    ("–±–ª—è–¥—å üí©", True),
    ("—Å—É–∫–∞ üëπ", True),
    ("–≥–∞–Ω–¥–æ–Ω üë∫", True),
    ("–º—É–¥–∞–∫ ü§°", True),
    ("–∑–∞–ª—É–ø–∞ üëª", True),
    ("—à–ª—é—Ö–∞ üçë", True),
    ("–ø–∏–¥–æ—Ä üè≥Ô∏è‚Äçüåà", True),
    ("üòà —Ö—É–π", True),
    ("üî• –ø–∏–∑–¥–∞", True),
    ("üñï –µ–±–∞–ª", True),
    ("üí© –±–ª—è–¥—å", True),
    ("üëπ —Å—É–∫–∞", True),
    
    # –ì—Ä–∞–Ω–∏—á–Ω—ã–µ –∫–µ–π—Å—ã –¥–ª–∏–Ω—ã
    ("–∞" * 1000, False),
    ("—Ö—É–π" * 300, True),
    ("–ø–∏–∑–¥–∞" * 200, True),
    ("–±–ª—è–¥—å" * 150, True),
    ("—Å—É–∫–∞" * 250, True),
    ("–ø" * 400 + "–∏–∑–¥–∞", True),
    ("–µ" * 300 + "–±–∞–ª", True),
    ("–±" * 200 + "–ª—è–¥—å", True),
    ("—Å" * 100 + "—É–∫–∞", True),
    
    # –†–µ–∞–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –æ–±—Ö–æ–¥–∞ —Ñ–∏–ª—å—Ç—Ä–æ–≤
    ("—Ö—É—é—à–∫–∏-–ø–ª—é—à–∫–∏", True),
    ("–ø–∏–∑–¥–∞—Ç–æ-–±–ª—è–¥—Å–∫–∏–π", True),
    ("–µ–±–∞—à–∏–ª–æ–≤–∫–∞", True),
    ("–±–ª—è–¥—é—à–Ω–∏–∫", True),
    ("—Å—É–∫–æ–¥–µ–ª—å–Ω–∏–∫", False),
    ("–≥–∞–Ω–¥–æ–Ω–æ–º–µ—Ç—Ä", True),
    ("–º—É–¥–∞–∫–æ—Å–∫–æ–ø", True),
    ("–∑–∞–ª—É–ø–æ–≥–ª–æ—Ç", True),
    ("—à–ª—é—Ö–æ–¥—Ä–æ—á–∫–∞", True),
    ("–ø–∏–¥–æ—Ä–≤–∞–ª—å–µ", True)]

BAD_WORDS_PATH = Path(__file__).parent.parent / "badwords.json"


class TestProfanityFilter:
    
    BAD_WORDS_PATH = Path(__file__).parent.parent / "badwords.json"
    
    def __init__(self, bad_words_file=BAD_WORDS_PATH):
        # 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è better_profanity
        profanity.load_censor_words()
        
        # —Å–ª–æ–≤–∞—Ä—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π
        self.data_mapping = DataProfanity.CHAR_REPLACEMENT_MAP
        self.min_word_length = 4
        self.special_chars = set('0123456789!@#$%^&*')
        profanity.CHARS_MAPPING.update(self.data_mapping)
        
        # 2. –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Å—Ç–æ–º–Ω—ã—Ö —Å–ª–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞
        self.bad_words = []
        
        if bad_words_file:
            try:
                with open(bad_words_file, 'r', encoding='utf-8') as json_f:
                    self.bad_words = json.load(json_f)
                    logger_tests.debug(f'–î–æ–±–∞–≤–ª—è—é—Ç—Å—è —Å–ª–æ–≤–∞')
                    profanity.add_censor_words(self.bad_words)
            
            except (FileNotFoundError, json.JSONDecodeError) as err:
                logger_tests.error(
                    f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ {bad_words_file}:{err}")
                self.bad_words = []
            except Exception as err:
                logger_tests.error(f'–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è JSON: {err}', exc_info=True)
        
        # 4. –ö–æ–º–ø–∏–ª—è—Ü–∏—è —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π
        self.base_pattern = re.compile(
            DataProfanity.base_pattern, flags=re.IGNORECASE)
        
        self.additional_patterns = [re.compile(pattern, flags=re.IGNORECASE) for
            pattern in DataProfanity.additional_patterns]
        
        # 5. –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è —Ä–∞–∑–±–∏–≤–∫–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Å–ª–æ–≤–∞
        self.word_pattern = re.compile(r'\b\w+\b')
    
    def is_profanity(self, text: str) -> bool:
        """
        –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        :param text:
        :return bool:
        """
        text = text.replace(" ", "")
        normalized_text = self._normalize_text(text)
        text_lower = str(normalized_text).lower()
        
        # Fast check
        if len(text_lower.strip()) < 3:
            return False
        
        # 1. –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ better_profanity
        if profanity.contains_profanity(text_lower):
            logger_tests.warning(
                '–§–∏–ª—å—Ç—Ä 1 better_profanity(–ø–æ–ª–Ω–æ–µ '
                '—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)')
            return True
        
        # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–º –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º
        if self.base_pattern.search(text_lower):
            logger_tests.warning('–§–∏–ª—å—Ç—Ä 2  re1')
            return True
        
        for pattern in self.additional_patterns:
            if pattern.search(text_lower):
                logger_tests.warning('–§–∏–ª—å—Ç—Ä 3 re2')
                return True
        
        # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —Å–ø–∏—Å–∫—É —Å–ª–æ–≤ (—Å —É—á–µ—Ç–æ–º –æ–ø–µ—á–∞—Ç–æ–∫)
        words = re.findall(r'\w+', text_lower)
        if any(word in self.bad_words for word in words):
            logger_tests.warning('–§–∏–ª—å—Ç—Ä 4 —Å —É—á–µ—Ç–æ–º –æ–ø–µ—á–∞—Ç–æ–∫')
            return True
        
        # 4. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        if self._check_levenshtein(text_lower):
            logger_tests.warning('–§–∏–ª—å—Ç—Ä 5 "Levenshtein"')
            return True
        return False
    
    def _normalize_text(self, text: str) -> str:
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        # –°–Ω–∞—á–∞–ª–∞ –∑–∞–º–µ–Ω—è–µ–º –≤—Å–µ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã –∏ –ø–æ—Ö–æ–∂–∏–µ –±—É–∫–≤—ã
        normalized = []
        for char in text.lower():
            replacement = char
            for base_char, variants in self.data_mapping.items():
                if char in variants:
                    replacement = base_char
                    break
            normalized.append(replacement)
        normalized_text = ''.join(normalized)
        
        # –£–¥–∞–ª—è–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Å–∏–º–≤–æ–ª—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä "–ø—Ä—Ä–∏–≤–µ—Ç" -> "–ø—Ä–∏–≤–µ—Ç")
        normalized_text = re.sub(r'(.)\1+', r'\1', normalized_text)
        return normalized_text
    
    def _is_valid_match(self, candidate: str, bad_word: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤–∞–ª–∏–¥–Ω—ã–º"""
        # –ï—Å–ª–∏ –≤ –∫–∞–Ω–¥–∏–¥–∞—Ç–µ –µ—Å—Ç—å —Ü–∏—Ñ—Ä—ã/—Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã - —Å—á–∏—Ç–∞–µ–º –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–º
        if any(c in self.special_chars for c in candidate):
            return True
        
        # –î–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–ª–æ–≤ (3-4 —Å–∏–º–≤–æ–ª–∞) —Ç—Ä–µ–±—É–µ–º —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        if len(bad_word) <= 4:
            return candidate == bad_word
        
        # –î–ª—è —Å–ª–æ–≤ –∏–∑ 5 —Å–∏–º–≤–æ–ª–æ–≤ - –º–∞–∫—Å–∏–º—É–º 1 –æ—à–∏–±–∫–∞
        if len(bad_word) == 5:
            return distance(candidate, bad_word) <= 1
        
        # –î–ª—è –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã—Ö —Å–ª–æ–≤ - –º–∞–∫—Å–∏–º—É–º 2 –æ—à–∏–±–∫–∏
        return distance(candidate, bad_word) <= 2
    
    def _check_levenshtein(self, phrase: str) -> bool:
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º"""
        normalized = self._normalize_text(phrase)
        words = re.findall(r'\b\w+\b', normalized)  # –≤—ã–¥–µ–ª—è–µ–º —Ü–µ–ª—ã–µ —Å–ª–æ–≤–∞
        
        for bad_word in self.bad_words:
            bw_len = len(bad_word)
            
            # –ù–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞
            if bw_len < self.min_word_length:
                continue
            
            for candidate in words:
                c_len = len(candidate)
                
                # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –¥–ª–∏–Ω–µ
                if abs(c_len - bw_len) > 2:  # –¥–æ–ø—É—Å–∫–∞–µ–º —Ä–∞–∑–Ω–∏—Ü—É –¥–æ 2 —Å–∏–º–≤–æ–ª–æ–≤
                    continue
                
                # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
                if candidate == bad_word:
                    logger_tests.warning(f'–¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: {bad_word}')
                    return True
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –õ–µ–≤–µ–Ω—à—Ç–µ–π–Ω–∞ —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                if self._is_valid_match(candidate, bad_word):
                    logger_tests.warning(
                        f'–ù–∞–π–¥–µ–Ω–æ –ø–æ –õ–µ–≤–µ–Ω—à—Ç–µ–π–Ω—É: {bad_word} '
                        f'(–∫–∞–Ω–¥–∏–¥–∞—Ç: {candidate}, —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ: {distance(candidate, bad_word)})')
                    return True
        
        return False

def test_comment_filter():
    profanity_filter = TestProfanityFilter()
    passed = 0
    
    for comment, expected in test_cases:
        result = profanity_filter.is_profanity(text=comment)
        if result == expected:
            passed += 1
            print(f'–ù–∞–π–¥–µ–Ω–æ: {comment}')
        else:
            print(
                f"–¢–µ—Å—Ç –ø—Ä–æ–≤–∞–ª–µ–Ω: '{comment}' | –û–∂–∏–¥–∞–ª–æ—Å—å: {expected}, –ü–æ–ª—É—á–µ–Ω–æ: {result}")
    
    print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç: {passed} –∏–∑ {len(test_cases)} —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–π–¥–µ–Ω–æ")
    print(f"–ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {passed / len(test_cases) * 100:.2f}%")


if __name__ == "__main__":
    test_comment_filter()
